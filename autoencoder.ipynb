{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37064bitbaseconda24c38771a7744f689cf6683cc835f426",
   "display_name": "Python 3.7.0 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import sys \n",
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7fb8e05590e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mPATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0minputs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m127\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m127\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtargets_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m127\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m127\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_data' is not defined"
     ]
    }
   ],
   "source": [
    "PATH = ''\n",
    "data = input_data.read_data_sets(\"\")\n",
    "\n",
    "inputs_ = tf.placeholder(tf.float32, [None, 127, 127, 3])\n",
    "targets_ = tf.placeholder(tf.float32, [None, 127, 127, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x, alpha = 0.1):\n",
    "    return tf.maximum(alpha * x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-396ce9c436f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en-convolutions'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     conv1 = tf.layers.conv2d(inputs_, \n\u001b[0m\u001b[0;32m      3\u001b[0m                             \u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                             \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                             \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inputs_' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('en-convolutions'):\n",
    "    conv1 = tf.layers.conv2d(inputs_, \n",
    "                            filters=3,\n",
    "                            kernel_size=(3, 3),\n",
    "                            strides=(1, 1),\n",
    "                            padding='SAME',\n",
    "                            use_bias=True,\n",
    "                            activation=lrelu,)\n",
    "#now 127x127x3\n",
    "with tf.name_scope('en_pooling'):\n",
    "    maxpool1 = tf.layers.max_pooling2d(conv1,\n",
    "                                      pool_size = (2,2),\n",
    "                                      striders = (2,2),\n",
    "                                      )\n",
    "#now 63X63x3\n",
    "with tf.name_scope('en-convolutions'):\n",
    "    conv2 = tf.layers.conv2d(maxpool1, \n",
    "                            filters=3,\n",
    "                            kernel_size=(3, 3),\n",
    "                            strides=(1, 1),\n",
    "                            padding='SAME',\n",
    "                            use_bias=True,\n",
    "                            activation=lrelu,)\n",
    "#now 63x63x3\n",
    "with tf.name_scope('en_pooling'):\n",
    "    maxpool2 = tf.layers.max_pooling2d(conv2,\n",
    "                                      pool_size = (2,2),\n",
    "                                      striders = (2,2),\n",
    "                                      )\n",
    "#now 31x31x3\n",
    "with tf.name_scope('en-convolutions'):\n",
    "    conv2 = tf.layers.conv2d(maxpool2, \n",
    "                            filters=3,\n",
    "                            kernel_size=(3, 3),\n",
    "                            strides=(1, 1),\n",
    "                            padding='SAME',\n",
    "                            use_bias=True,\n",
    "                            activation=lrelu,)\n",
    "#now 31x31x3\n",
    "with tf.name_scope('en_pooling'):\n",
    "    encoded = tf.layers.max_pooling2d(conv3,\n",
    "                                      pool_size = (2,2),\n",
    "                                      striders = (2,2),\n",
    "                                      )\n",
    "#now 15x15x3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('decoder'):\n",
    "    conv3 = tf.layers.conv2d(encoded,\n",
    "                            filters=33,\n",
    "                            kernel_size=(3, 3),\n",
    "                            strides=(1,1),\n",
    "                            padding='SAME',\n",
    "                            use_bias=True,\n",
    "                            activation=lrelu)\n",
    "#now 15x15x3\n",
    "    upsamples1 = tf.layers.conv2d_transpose(conv3,\n",
    "                                            filters = 3\n",
    "                                            kernel_size = 3\n",
    "                                            padding = 'SAME', \n",
    "                                            strides = 2, \n",
    "                                            name = 'upsamples1')\n",
    "    upsamples2 = tf.layers.conv2d_transpose(conv3,\n",
    "                                            filters = 3\n",
    "                                            kernel_size = 3\n",
    "                                            padding = 'SAME', \n",
    "                                            strides = 2, \n",
    "                                            name = 'upsamples2')\n",
    "    upsamples3 = tf.layers.conv2d_transpose(conv3,\n",
    "                                            filters = 3\n",
    "                                            kernel_size = 3\n",
    "                                            padding = 'SAME', \n",
    "                                            strides = 2, \n",
    "                                            name = 'upsamples3')"
   ]
  }
 ]
}